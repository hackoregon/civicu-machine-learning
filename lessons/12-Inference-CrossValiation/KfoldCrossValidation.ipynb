{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "You can find a link to variable explanations [here](https://www.openintro.org/stat/data/?data=ames)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into dataframe\n",
    "ames = pd.read_csv(\"https://www.openintro.org/stat/data/ames.csv\")\n",
    "# remove special characters from variable names\n",
    "ames.columns = [c.replace(\".\",\"\") for c in ames.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(ames)\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not touch that test set until after you have chosen your model. Make sure to use the same training set throughout this exercise. After you have run the k-fold validation to select a model, you can use the test set to estimate error in unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samp = train[[\"GrLivArea\", \"LotArea\"]]\n",
    "y_samp = train[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm-up Exercise: \n",
    "Prove to yourself that each observation appears in a k_test set exactly once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_samp = LinearRegression(normalize=True)\n",
    "k_rmse = [] # this way we can see what the error is for each test fold\n",
    "for k_train_idx, k_test_idx in KFold(k).split(X_samp):\n",
    "    model_samp.fit(X_samp.iloc[k_train_idx], y_samp.iloc[k_train_idx])\n",
    "    k_rmse.append(np.sqrt(mean_squared_error(y_samp.iloc[k_test_idx], model_samp.predict(X_samp.iloc[k_test_idx]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(k_rmse), stats.sem(k_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Work with your neighbors to agree on a few models to try. Each of you run the k-fold cross validation on every model you agree to. Compare your CV scores for each model, as well as the final model selection and error on the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
