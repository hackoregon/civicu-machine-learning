{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Exam: Hands-On Portion\n",
    "\n",
    "\n",
    "**Instructions**\n",
    "This should take 1 - 2 hours of time. Do your best! We'll be grading not based accuracy, but on comprehension of the problem, the methods noted, and your approach. Good luck! \n",
    "\n",
    "### **The Challenge**\n",
    "\n",
    "The executive team is interested in a user class called **\"Adopted Users\"** for its cloud project collaboration platform. \n",
    "\n",
    "What's an \"Adopted User\"?\n",
    "- The team has defined this as a user who **logs in at least once a day across 3 days in seven day period**. \n",
    "\n",
    "- This means, Chris is a super user if he logs in on Monday, Wednesday and Friday. He's also a super user if he logs in Tuesday, Friday, then the following Monday. Thus the problem deals with \"rolling\" periods. \n",
    "\n",
    "**A. Use time-series data in the table \"user_engagement.csv\" to tag these users**.\n",
    "\n",
    "After identifying these users, the team would like to find out: \n",
    "\n",
    "**B. \"What factors drives users to become 'Adopted Users'\"? **\n",
    "\n",
    "This means a mixture of exploratory data analysis, feature engineer, model, crossvalidation and parameter tuning, and finally running feature importance. Feel free to use your creativity and explore and think through other potential solutions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "raw_users = pd.read_csv('./users.csv', encoding='latin-1')\n",
    "raw_user_engagement = pd.read_csv('./user_engagement.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Dictionary:**\n",
    "\n",
    "A. user_engagement.csv\n",
    "- time_stamp: mm/dd/yyy hh:mm:ss\n",
    "- user_id\n",
    "- visited: 1, indicating that they visited \n",
    "\n",
    "B. users.csv\n",
    "- name:  the  user's  name\n",
    "- object_id: the  user's  id\n",
    "- email: email address\n",
    "-  creation_source: How was account created?\n",
    "    - personal_projects: invited to join another user's personal workspace\n",
    "    - guest_invite: invited to an organization as a guest (limited permissions)\n",
    "    - org_invite: invited to an organization (as a full member)\n",
    "    - signup: signed up via the website\n",
    "    - signup_google_auth: signed up using google authentication (using a google email account for their login id)\n",
    "    \n",
    "- creation_time:  when  they  created  their  account\n",
    "- last_session_creation_time:   unix  timestamp  of  last  login\n",
    "- opted_in_to_mailing_list:  whether  they  have  opted  into  receiving\n",
    "marketing  emails\n",
    "- enabled_for_marketing_drip:  whether  they  are  on  the  regular\n",
    "marketing  email  drip\n",
    "- org_id:   the  organization  (group  of  users)  they  belong  to\n",
    "- invited_by_user_id:   which  user  invited  them  to  join  (if  applicable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore \n",
    "1. User Desribe and Head to explore your two datasets\n",
    "2. create a few bar plots to explore your data\n",
    "- [Some ideas](https://machinelearningmastery.com/quick-and-dirty-data-analysis-with-pandas/)\n",
    "3. How many unique user_ids are there in each table? in both?\n",
    "\n",
    "List out some cleansing steps and note things you might have to have you do in order to get your data set into a feature frame and a target frame.\n",
    "\n",
    "Helpful functions: \n",
    "- is.in, groupby, plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Create your Target Variable\n",
    "1. You want to use a combination of steps to create a rolling 7 day period window. This rolling window of 7 days should count the number of log-ins. \n",
    "2. (optional) Execute any additional Exploratory Data analysis (EDA) you wish:\n",
    "\n",
    "        Exploratory Data Analysis (EDA) is used on the one hand to answer questions, test business assumptions, generate hypotheses for further analysis. On the other hand, you can also use it to prepare the data for modeling. The thing that these two probably have in common is a good knowledge of your data to either get the answers that you need or to develop an intuition for interpreting the results of future modeling.\n",
    "\n",
    "\n",
    "A few helpful methods in pandas\n",
    "- [to_period](https://stackoverflow.com/questions/23840797/convert-a-column-of-timestamps-into-periods-in-pandas)\n",
    "- [groupby](https://www.google.com/search?q=groupby&oq=groupby&aqs=chrome..69i57j0l2j69i60l3.1487j1j4&sourceid=chrome&ie=UTF-8)\n",
    "- [resample](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.resample.html)\n",
    "- [rolling](http://pandas.pydata.org/pandas-docs/stable/computation.html#window-functions)\n",
    "\n",
    "Inputs:\n",
    "- user_engagement\n",
    "\n",
    "Output: \n",
    "- Call your target dataframe \"target\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagement = raw_user_engagement\n",
    "\n",
    "# target = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleanse  + Feature Engineering:\n",
    "- Are there any steps you need to take to cleanse the data some more?\n",
    "- Do you need to apply any masks?\n",
    "- Do you need to take care of missing data? \n",
    "- Anything you need to drop? Things that don't make sense to include as a feature? .drop(['col1','col2'], axis = 1)\n",
    "- Can you think of any features to create?\n",
    "- do you need to one hot encode? pd.get_dummies or OneHotEncode from sklearn\n",
    "\n",
    "Other useful functions:\n",
    "- pd.concat([df1,df2], axis = 1) -- this will bind two dataframes column wise\n",
    "\n",
    "Outputs: \n",
    "- y, your target \n",
    "- X, a dataframe for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = raw_users \n",
    "\n",
    "\n",
    "#X = \n",
    "#y = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Train Test Split\n",
    "- use \"train_test_split\" from sklearn.model_selection.\n",
    "- use random_state = 100 \n",
    "- test_size = .15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = \n",
    "# X_train.shape,y_train.shape, X_test.shape, y_test.shape,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Modeling\n",
    "- Choose 1 or 2 classifier (or regressors, depending on what your target variable is)\n",
    "- use some cross validation and parameter optimization techiniques[hints here](https://github.com/hackoregon/civicu-machine-learning/blob/master/lessons/13-Hyperparameter-Optimization/Class%2013%20-%20Part%201%2C%20Hyper%20Parameter%20Tuning.ipynb):\n",
    "    - cross validaiton\n",
    "    - manaul search \n",
    "    - random search or gridsearch\n",
    "- choose a scoring method (depends on classificaton or regression task)\n",
    "\n",
    "\n",
    "\n",
    "Hint:\n",
    "- If your gridsearch doesn't work, try X_train.values y_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Test Performance on holdout data  (x_test, y_test)\n",
    "1. Which performance metric would you use for this?\n",
    "2. Bring up confusion matrix from confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "#y_pred_in =  # your predictions\n",
    "#y_test_in =  # your true ys\n",
    "#print(classification_report(y_pred=y_pred_in, y_true=y_test_in))\n",
    "#print(confusion_matrix(y_pred=y_pred_in, y_true=y_test_in))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Importance\n",
    "- Goal: Create a table with two columns: Variable and Importance. Sort by Importance. \n",
    "- Use either [permutation Feature Importance (may take a while)](https://github.com/hackoregon/civicu-machine-learning/blob/master/lessons/13-Hyperparameter-Optimization/Class%2013%20-%20Part%202%2C%20Permutation%20Feature%20Importance.ipynb) or [RandomForest's Feature Importance method](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Variable, Importance]\n",
       "Index: []"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame(\n",
    "    {'Variable': [], \n",
    "     'Importance':[]},\n",
    "    columns = [\"Variable\", \"Importance\"])\\\n",
    "    .sort_values('Importance', ascending = False)\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Story Telling\n",
    "- What are your next steps now? \n",
    "- What do you want to tell leadership?\n",
    "- How confident are you with this information?\n",
    "- Are there additional steps or data sets that you'd like to perform?\n",
    "\n",
    "Write 1 to 2 paragraphs or a a few bullet points discussing the above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
